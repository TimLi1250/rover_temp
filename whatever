#!/usr/bin/env python3
import os
import argparse
import time
import yaml

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image

###############################
# 1. Dataset Definition
###############################

class YOLODataset(Dataset):
    """
    A simple dataset class that expects images and corresponding label files.
    """
    def __init__(self, images_dir, labels_dir, img_size=640, transform=None):
        self.images_dir = images_dir
        self.labels_dir = labels_dir
        self.img_size = img_size
        self.transform = transform
        # Consider common image extensions
        self.image_files = sorted([f for f in os.listdir(images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
    
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        # Load image
        img_path = os.path.join(self.images_dir, self.image_files[idx])
        label_path = os.path.join(self.labels_dir, os.path.splitext(self.image_files[idx])[0] + '.txt')
        image = Image.open(img_path).convert('RGB')
        if self.transform:
            image = self.transform(image)
        else:
            image = transforms.ToTensor()(image)
        
        # Load labels: each line: class x_center y_center width height
        boxes = []
        if os.path.exists(label_path):
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) == 5:
                        cls, xc, yc, w, h = map(float, parts)
                        boxes.append([cls, xc, yc, w, h])
        # If no labels, return an empty tensor of shape (0,5)
        boxes = torch.tensor(boxes) if boxes else torch.zeros((0, 5))
        return image, boxes

###############################
# 2. Model Definition (YOLOv11)
###############################

class YOLOv11(nn.Module):
    """
    A minimal YOLOv11-style model.
    
    For simplicity, we build a small CNN backbone followed by a 1x1 conv detection head.
    The network outputs a tensor reshaped as (B, H, W, anchors, (nc+5)),
    where H and W are determined by the input size (we assume input size 640 becomes 20x20).
    """
    def __init__(self, cfg=None, nc=3, anchors=3):
        super(YOLOv11, self).__init__()
        self.nc = nc
        self.anchors = anchors
        # Each detection prediction has (nc + 5) numbers: class probabilities, 4 box coordinates, and objectness.
        self.out_channels = (nc + 5) * anchors
        # Simple backbone: Convolutions with pooling to reduce spatial dimensions
        self.backbone = nn.Sequential(
            nn.Conv2d(3, 32, 3, stride=1, padding=1),  # 640x640 -> 640x640
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2),                          # 640 -> 320
            nn.Conv2d(32, 64, 3, stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2),                          # 320 -> 160
            nn.Conv2d(64, 128, 3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(2),                          # 160 -> 80
            nn.Conv2d(128, 256, 3, stride=1, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.MaxPool2d(2),                          # 80 -> 40
            nn.Conv2d(256, 512, 3, stride=1, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.MaxPool2d(2)                           # 40 -> 20
        )
        # Detection head: output a (B, out_channels, 20, 20) feature map
        self.head = nn.Conv2d(512, self.out_channels, 1)  # 1x1 convolution
    
    def forward(self, x):
        x = self.backbone(x)  # (B, 512, 20, 20) for 640x640 input images
        x = self.head(x)      # (B, out_channels, 20, 20)
        B, C, H, W = x.shape
        # Reshape to (B, H, W, anchors, nc+5)
        x = x.view(B, self.anchors, self.nc + 5, H, W).permute(0, 3, 4, 1, 2)
        return x

###############################
# 3. Loss and Checkpoint Functions
###############################

def compute_loss(preds, targets, model):
    """
    Dummy loss function.
    
    In a full YOLO implementation you would:
      - Match predictions to ground truth via anchor matching.
      - Compute losses for bounding box coordinates, objectness, and classification.
    
    Here we simply compute an MSE loss between the predictions and a dummy target (zeros).
    This is only for demonstration and must be replaced by a proper YOLO loss.
    """
    dummy_target = torch.zeros_like(preds)
    loss = nn.MSELoss()(preds, dummy_target)
    return loss, {}

def save_checkpoint(model, optimizer, epoch, path):
    state = {
        'model': model.state_dict(),
        'optimizer': optimizer.state_dict(),
        'epoch': epoch,
    }
    torch.save(state, path)

###############################
# 4. Training and Validation Loops
###############################

def train_one_epoch(model, dataloader, optimizer, device):
    model.train()
    epoch_loss = 0.0
    for batch_idx, (imgs, targets) in enumerate(dataloader):
        imgs = imgs.to(device)
        # In a full implementation, targets must be encoded to the same shape as predictions.
        optimizer.zero_grad()
        preds = model(imgs)
        loss, _ = compute_loss(preds, targets, model)
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item()
        if batch_idx % 10 == 0:
            print(f'Batch {batch_idx}/{len(dataloader)} Loss: {loss.item():.4f}')
    return epoch_loss / len(dataloader)

def validate(model, dataloader, device):
    model.eval()
    total_loss = 0.0
    with torch.no_grad():
        for imgs, targets in dataloader:
            imgs = imgs.to(device)
            preds = model(imgs)
            loss, _ = compute_loss(preds, targets, model)
            total_loss += loss.item()
    return total_loss / len(dataloader)

###############################
# 5. Main Training Function
###############################

def main(args):
    device = torch.device(args.device if torch.cuda.is_available() else 'cpu')
    
    # Load dataset configuration from YAML.
    with open(args.data, 'r') as f:
        data_config = yaml.safe_load(f)
    train_images = data_config['train_images']
    train_labels = data_config['train_labels']
    val_images = data_config.get('val_images', train_images)
    val_labels = data_config.get('val_labels', train_labels)
    nc = data_config['nc']  # number of classes
    names = data_config['names']
    
    # Define image transformations.
    transform_train = transforms.Compose([
        transforms.Resize((args.img, args.img)),
        transforms.ToTensor(),
    ])
    transform_val = transforms.Compose([
        transforms.Resize((args.img, args.img)),
        transforms.ToTensor(),
    ])
    
    # Create datasets and dataloaders.
    train_dataset = YOLODataset(train_images, train_labels, img_size=args.img, transform=transform_train)
    val_dataset = YOLODataset(val_images, val_labels, img_size=args.img, transform=transform_val)
    
    train_loader = DataLoader(train_dataset, batch_size=args.batch, shuffle=True, num_workers=4, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=args.batch, shuffle=False, num_workers=4, pin_memory=True)
    
    # Initialize the model.
    model = YOLOv11(cfg=args.cfg, nc=nc).to(device)
    if args.weights != '':
        checkpoint = torch.load(args.weights, map_location=device)
        model.load_state_dict(checkpoint['model'])
        print(f"Loaded weights from {args.weights}")
        
    # Set up optimizer and learning rate scheduler.
    optimizer = optim.SGD(model.parameters(), lr=args.learning_rate, momentum=0.9, weight_decay=5e-4)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.learning_rate_period, gamma=args.learning_rate_decay)
    
    best_val_loss = float('inf')
    for epoch in range(args.epochs):
        print(f"Epoch {epoch+1}/{args.epochs}")
        start_time = time.time()
        train_loss = train_one_epoch(model, train_loader, optimizer, device)
        val_loss = validate(model, val_loader, device)
        scheduler.step()
        epoch_time = time.time() - start_time
        print(f"Epoch {epoch+1} completed in {epoch_time:.2f}s, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}")
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            save_checkpoint(model, optimizer, epoch, args.checkpoint_path)
            print(f"Checkpoint saved at epoch {epoch+1}")
    print("Training complete.")

###############################
# 6. Argument Parsing and Script Entry
###############################

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--data', type=str, required=True, help='Path to dataset YAML file')
    parser.add_argument('--cfg', type=str, required=True, help='Model configuration file (e.g., yolov11.yaml)')
    parser.add_argument('--weights', type=str, default='', help='Path to initial weights (leave empty to train from scratch)')
    parser.add_argument('--batch', type=int, default=16, help='Batch size')
    parser.add_argument('--epochs', type=int, default=100, help='Number of training epochs')
    parser.add_argument('--img', type=int, default=640, help='Input image size')
    parser.add_argument('--learning_rate', type=float, default=0.01, help='Initial learning rate')
    parser.add_argument('--learning_rate_decay', type=float, default=0.1, help='Learning rate decay factor')
    parser.add_argument('--learning_rate_period', type=int, default=50, help='Epoch period for learning rate decay')
    parser.add_argument('--checkpoint_path', type=str, default='checkpoint.pt', help='Path to save model checkpoint')
    parser.add_argument('--device', type=str, default='cuda', help='Device to use for training')
    
    args = parser.parse_args()
    main(args)
